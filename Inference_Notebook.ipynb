{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373eccd-c127-4030-8f1c-b560f0322b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afb 189 unannotated.bmp: TP=0, FP=0, FN=2\n",
      "afb139 unannotated.bmp: TP=0, FP=0, FN=2\n",
      "0.0 0.0\n",
      "0.0 0.0259552001953125\n",
      "afb142 unannotated.bmp: TP=0, FP=2, FN=2\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "afb 158 unannotated.bmp: TP=0, FP=9, FN=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "from model import get_model\n",
    "from utils import merge_boxes\n",
    "\n",
    "\n",
    "IMAGE_DIR = \"data/images\"\n",
    "ANN_DIR   = \"data/annotations\"\n",
    "OUT_DIR   = \"eval_visuals\"\n",
    "\n",
    "MODEL_PATH = \"afb_fcos2.pth\"\n",
    "\n",
    "TILE = 256\n",
    "OVERLAP = 64\n",
    "SCORE_THRESH = 0.4\n",
    "IOU_THRESH = 0.5\n",
    "\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = get_model().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def compute_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    union = areaA + areaB - inter\n",
    "\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "# ---------- Matching ----------\n",
    "def match_predictions(pred_boxes, gt_boxes):\n",
    "    matched = set()\n",
    "    tp = fp = 0\n",
    "\n",
    "    for pb in pred_boxes:\n",
    "        best_iou = 0\n",
    "        best_j = -1\n",
    "\n",
    "        for j, gb in enumerate(gt_boxes):\n",
    "            if j in matched:\n",
    "                continue\n",
    "            iou = compute_iou(pb, gb)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_j = j\n",
    "\n",
    "        if best_iou >= IOU_THRESH:\n",
    "            tp += 1\n",
    "            matched.add(best_j)\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    fn = len(gt_boxes) - len(matched)\n",
    "    return tp, fp, fn\n",
    "\n",
    "\n",
    "def infer_image(img):\n",
    "    H, W, _ = img.shape\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "\n",
    "    for y in range(0, H - TILE + 1, TILE - OVERLAP):\n",
    "        for x in range(0, W - TILE + 1, TILE - OVERLAP):\n",
    "            tile = img[y:y+TILE, x:x+TILE]\n",
    "\n",
    "            t = torch.from_numpy(tile).permute(2, 0, 1).float() / 255.0\n",
    "            t = t.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(t)[0]\n",
    "\n",
    "            for b, s in zip(out[\"boxes\"], out[\"scores\"]):\n",
    "                if s >= SCORE_THRESH:\n",
    "                    b = b.cpu().numpy()\n",
    "                    all_boxes.append([\n",
    "                        b[0] + x, b[1] + y,\n",
    "                        b[2] + x, b[3] + y\n",
    "                    ])\n",
    "                    all_scores.append(float(s))  \n",
    "\n",
    "    if not all_boxes:\n",
    "        return []\n",
    "\n",
    "    boxes = torch.tensor(all_boxes, dtype=torch.float32, device=device)\n",
    "    scores = torch.tensor(all_scores, dtype=torch.float32, device=device)\n",
    "\n",
    "    boxes, scores = merge_boxes(boxes, scores, iou=0.3)\n",
    "    return boxes.tolist()\n",
    "\n",
    "\n",
    "total_tp = total_fp = total_fn = 0\n",
    "\n",
    "for fname in os.listdir(IMAGE_DIR):\n",
    "    name = fname.lower().strip()\n",
    "    if \"unannotated.bmp\" not in name:\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(IMAGE_DIR, fname)\n",
    "    ann_path = os.path.join(\n",
    "        ANN_DIR,\n",
    "        name.replace(\"unannotated.bmp\", \"annotated.json\")\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(ann_path):\n",
    "        print(f\"Missing annotation for {fname}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    with open(ann_path) as f:\n",
    "        gt_boxes = json.load(f)[\"boxes\"]\n",
    "\n",
    "    pred_boxes = infer_image(img)\n",
    "\n",
    "    tp, fp, fn = match_predictions(pred_boxes, gt_boxes)\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "\n",
    "    \n",
    "    vis = img.copy()\n",
    "\n",
    "   \n",
    "    for x1, y1, x2, y2 in gt_boxes:\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            vis,\n",
    "            (int(x1), int(y1)),\n",
    "            (int(x2), int(y2)),\n",
    "            (0, 0, 255),\n",
    "            2\n",
    "        )\n",
    "\n",
    "\n",
    "    for x1, y1, x2, y2 in pred_boxes:\n",
    "        \n",
    "        print(x2 - x1, y2 - y1)\n",
    "        cv2.rectangle(\n",
    "            vis,\n",
    "            (int(x1), int(y1)),\n",
    "            (int(x2), int(y2)),\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, fname.replace(\".bmp\", \"_eval.png\"))\n",
    "    cv2.imwrite(out_path, vis)\n",
    "\n",
    "    print(f\"{fname}: TP={tp}, FP={fp}, FN={fn}\")\n",
    "\n",
    "\n",
    "precision = total_tp / (total_tp + total_fp + 1e-6)\n",
    "recall    = total_tp / (total_tp + total_fn + 1e-6)\n",
    "\n",
    "print(\"\\n==== FINAL METRICS ====\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a5f6d-0820-420d-81ea-d5bfb11b114f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
